### Videos
- https://www.youtube.com/@AICodeKing/videos
- https://www.youtube.com/@aiexplained-official
- https://bloomberg.github.io/foml/ - foundations of machine learning
### Articles & blogs
- https://github.com/decodingai-magazine
- https://simonwillison.net/2025/Dec/31/the-year-in-llms/
- https://www.aihero.dev/a-complete-guide-to-agents-md
- https://steve-yegge.medium.com/welcome-to-gas-town-4f25ee16dd04
	- a crazy multi-agent orchestration idea + tooling
### Books
- https://pragprog.com/titles/jwpaieng/a-common-sense-guide-to-ai-engineering/
### Courses
- https://agenticjumpstart.com/ - payed
### Other resources
- https://artificialanalysis.ai/
	- velmi dukladny porovnani modelu podle vsemoznych vlastnosti
- https://openrouter.ai/models?fmt=cards&order=most-popular&categories=programming
	- most popular models with details
- https://openrouter.ai/rankings
	- model usage rankings (graphs)
- https://openrouter.ai/chat?room=orc-1769070174-VAhvadxXn6nHuyXe6UAT
	- zaznam z multi-module chat roomu pro srovnani modelu pri stejnem zadani
	- na elixir vypada trochu lepsi MiniMax M2.1, na kotlin vypada lepsi GLM 4.7 (je to teda podle jednoho prikladu), MiMo-V2-Flash na elixir nic moc, kotlin vypada slusne
	- zajimavy je, ze i mnozstvi reasoningu se jim razantne otoci - u elixiru MM reasonuje jako blazen, glm o dost min (byt furt dost), u kotlinu o dost vic reasonuje glm