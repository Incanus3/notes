=== Tue, 6.10. ===

- 10-12 - oprava datastore-common transaction testu
  - gitlab-runner pouziva tornado-utils a datastore-common z
    /home/gitlab-runner/sources/alto-tornado-utils, to ale nemuze fungovat po aktualizaci - bud
    zaktualizovat jejich zdrojaky, nebo upravit PYTHONPATH tak, aby pouzival build slozku
  - idealni by bylo mit je jako baliky, ktere by se instalovaly z repa (pred spustenim buildu)
  - pip zvlada - http://pip.readthedocs.org/en/stable/reference/pip_install/#git, ale je treba
    nastavit install.py

- 15.30-20.30
  - studium python packagingu

  made tornado_utils pip installable
  - added setup.py
  - moved all code into alto_tornado_utils subdir
  - renamed tornado_utils to alto_tornado_utils to avoid conflict with existing package
  - updated imports
  - added __init__.py files

  made datastore_common pip installable
  - added setup.py
  - added __init__.py files
  - moved all code into datastore_common subdir
  - updated gitlab ci config

  updated datastore_rezervace after making datastore_common pip installable
  - added datastore_common to requirements.txt
  - updated imports
  - updated gitlab ci config
  - updated db config example
  - updated readme

  updated datastore_food after making datastore_common pip installable
  - added datastore_common to requirements.txt
  - updated imports
  - updated gitlab ci config
  - updated db config example
  - updated readme

- 21.30-1 - promysleni reseni problemu s migracemi
  - studium dockeru a vagrantu

= 10h30

=== Python packaging ===

pip install -e .
- muze byt pouzito pro nainstalovani baliku v cwd - mohlo by resit napr. testy v datastore-common
  (ktery importuje svoje moduly pres fqn, aby je odlisil od modulu projektu, ktery ho pouziva a
  napr. dedi jeho tridy)
-e git+https://somerepo/bar.git#egg=bar
- je zda se validni forma radku v requirements.txt
"Requirements Files described most simply, are just a list of pip install arguments placed into a file"
http://gitlab.altopraha.mine.nu:10080/python/alto-tornado-utils/repository/archive.zip?ref=master

=== Problem s migracemi z nekolika zdroju ===
- s migracema je oser v tom, ze musim projit tri ruzny repa (vedet kde jsou nasazeny), upravit
  jejich db config a spustit ve spravnem poradi migrace
- kdybych repa s migracemi dostupny lokalne (vnorene) a mohl je pustit vsechny se stejnym db
  configem, bylo by idealni
- pro ds migrace snadno udelam subrepa, spustitelna alembicem oddelene
- rezervace vyzaduji pro svou funkci migrace ds (ne primo pro sebe, ale potrebuji s nim
  komunikovat) - to je ale logicke - ds stejne musim nasadit jako druhou sluzbu, tak spustim jeho
  migrace
- ds vyzaduje migrace railsu - zpristupnuje jejich tabulky
- v praxi to neni problem, nebot stejne instaluju obe sluzby a migrace se proste pousti postupne
  na vsech stranach, v poradi, v jakem vznikaji, nevraci se
- problem je pri testovani, kde je potreba pustit je oddelene, kazdy projekt najedou od zacatku do
  konce (prestoze se mohly prolinat, napr. do sk_headers je pridan order_id fk az po vytvoreni
  orders tabulky a casto potrebuju vsechny i kdyz testuju pouze jeden projekt
- potrebovalo by tedy jeden mechanismus, ktery zvladne migrace z vice zdroju (tedy nutnost mit je
  vsechny v jednom jazyce a spustitelne jednou knihovnou) a migrace razene podle timestampu,
  nikoli backlinkem
- prolinani zatim ale neni enormni problem, zatim existuje spravne poradi, ve kterem lze spustit
  po sobe po projektech
  - rails (pokud spusteno po ds-common, rve ze uz existuje clients, v ds-common je osetreno)
    - v rails by slo osetrit taky, ale pak by muselo byt zajisteno, ze rails a ds-common migrace
      tabulky budou kept in sync, jistejsi asi je, mit jeden autoritativni zdroj (zatim rails)
  - ds-common
  - ds (vyzaduje rails i ds-common)
- problem ale zustava s nutnosti nasadit cely druhy a treti projekt, prejit do nej, upravit db.yml
  a spustit migrace
- kdyby byly migrace v subrepech a jednoduse spustitelne z kazdeho projektu, bylo by to
  nesrovnatelne pohodlnejsi

- druhou moznosti je neco typu docker (nebo vagrant?), ktere nainstaluje a rozjede cele prostredi
  v konfiguraci vhodne pro vyvoj, test, nebo produkci (to ovsem stale neresi pripadny problem s
  prolinanim migraci)
- ten by zaroven vyresil i problem instalatoru
- a gitlab ci ma integraci s dockerem

=== Vagrant & Docker ===
- docker je super rychly, ale defaultne je urcen k tomu, aby kazdy box spoustel jednu sluzbu
  (napr. postgres, nebo web app), ty lze pak pospojovat dohromady
- lze obejit napr. pomoci http://tiborsimko.org/docker-running-multiple-processes.html
- treba ale sestavovat konkretni prikazy pro spusteni sluzeb - pusobi counterintuitivne

- runtime po provedeni direktiv RUN a EXEC neprezije - build po kazdem kroku snapshotne stav
  disku, do ktereho je image obnoven
- prezije pouze to, co se spusti pomoci CMD (muze byt jen 1), prip. ENTRY_POINT
- kdyby ale entry_point volal skript, ktery spusti sluzby a pak prikaz, ktery dostane na vstupu,
  melo by tez fungovat
- entry point skript z https://docs.docker.com/articles/dockerfile_best-practices/ ENTRYPOINT zda
  se dela presne tohle

- provisioning a popropojovani containeru nakonec nemusi byt tak slozite, jak se zda, podle
  http://doc.gitlab.com/ci/docker/using_docker_images.html to vypada celkem jednoduse

- vagrant je podstatne pomalejsi (pousti komplet vm pres vbox), ale s boxem se pracuje jako s
  plnohodnotnym strojem
- vagrant navic nema tak chytry provisioning jako docker (ktery pri buildu udela snapshot po
  kazdem kroku, takze se pak spousti jenom ty nove)
- lze ale vyresit tak, ze se vytvori jeden Vagrantfile, ktery z nejakeho existujiciho base boxu
  (napr. ubuntu/trusty64) naprovisionuje pripraveny stroj, z toho pak pomoci vagrant package
  vytvorit novy base box a ten pak spoustet
